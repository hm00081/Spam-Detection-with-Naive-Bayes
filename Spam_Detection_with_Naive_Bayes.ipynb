{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-fuPyC9FsJb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import re\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import urllib.request"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. 데이터 로드 및 전처리\n",
        "#spam.csv 파일을 불러와서 불필요한 칼럼을 삭제\n",
        "#레이블을 수치형으로 변환 (ham -> 0, spam -> 1)\n",
        "#중복된 텍스트를 삭제\n",
        "\n",
        "#2. 훈련 및 테스트 데이터 분할\n",
        "#train_test_split을 사용하여 데이터를 훈련 및 테스트 세트로 분할\n",
        "\n",
        "#3. 토큰화\n",
        "#Tokenizer를 사용하여 훈련 데이터를 토큰화\n",
        "#이 토큰화된 데이터는 RNN 모델에 사용\n",
        "\n",
        "#4. 데이터 탐색 및 시각화\n",
        "#스팸 메일과 정상 메일의 분포를 확인\n",
        "#메일의 길이 분포에 대한 시각화도 진행\n",
        "\n",
        "#5. 텍스트 전처리\n",
        "#NLTK의 stopwords와 구두점(punctuation)을 사용하여 메일 내의 불필요한 단어나 문자를 제거\n",
        "#전처리된 텍스트에서 스팸 메일과 정상 메일의 가장 빈번한 단어를 확인\n",
        "\n",
        "#6. RNN을 사용한 스팸 메일 분류\n",
        "#임베딩층, RNN, 및 Dense 층을 포함하는 심층 신경망을 구성\n",
        "#모델을 훈련 데이터에 학습시키고 테스트 데이터에 대한 성능을 평가\n",
        "\n",
        "#7. 모델의 손실 시각화\n",
        "#훈련 및 검증 손실을 시각화하여 모델의 학습 과정을 확인\n"
      ],
      "metadata": {
        "id": "Sz0Uu8s0lvcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Spam mail data url\n",
        "url = \"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/10.%20RNN%20Text%20Classification/dataset/spam.csv\"\n",
        "\n",
        "urllib.request.urlretrieve(url, filename=\"spam.csv\")\n",
        "data = pd.read_csv('spam.csv', encoding='latin1')\n",
        "print('총 메일 수 :',len(data))"
      ],
      "metadata": {
        "id": "bVCvPoF_Fxy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Raw data head\n",
        "data.head()"
      ],
      "metadata": {
        "id": "jzvkgm5xmTTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unwanted columns and rename remaining columns\n",
        "if len(data.columns) > 3:\n",
        "    data = data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1)\n",
        "if data.columns[0] != 'label':\n",
        "    data = data.rename(columns={'v1': 'label', 'v2': 'text'}) # ham :일반, spam: 스팸\n",
        "data.head()"
      ],
      "metadata": {
        "id": "i4Gx-gUyLVef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "h213IOQF1sCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupby('label').describe()"
      ],
      "metadata": {
        "id": "DJCaQEjE1xQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert label to numerical variable (정수형태로 구분)\n",
        "data['label'] = data.label.map({'ham': 0, 'spam': 1}) # spam to 1, ham to 0\n",
        "data['message_len'] = data['text'].apply(len)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "5eA5WhzHoHz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Delete duplicate E-mail\n",
        "data.drop_duplicates(subset=['text'], inplace=True)\n",
        "print('중복삭제한 이메일 수 :',len(data))"
      ],
      "metadata": {
        "id": "BDIhAsw1qmHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_data = data['text']\n",
        "y_data = data['label'] #data1,2 to x, y data"
      ],
      "metadata": {
        "id": "VV3nW7sQpKr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=0, stratify=y_data) # 0.2로 했는데, 0.1로 하면?"
      ],
      "metadata": {
        "id": "gOlGqsfcpNdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_encoded = tokenizer.texts_to_sequences(X_train)\n",
        "print(X_train_encoded[:5])"
      ],
      "metadata": {
        "id": "dIR9PBnprWK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Words key-value dictionary\n",
        "word_to_index = tokenizer.word_index\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "id": "2Fy2QN6QwT3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(word_to_index) + 1\n",
        "print('단어 집합 사이즈: {}'.format((vocab_size)))"
      ],
      "metadata": {
        "id": "5YINrsI2wcIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 189\n",
        "X_train_padded = pad_sequences(X_train_encoded, maxlen = max_len)\n",
        "print(\"훈련 데이터의 크기:\", X_train_padded.shape)"
      ],
      "metadata": {
        "id": "-Nux_3oXw5Ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# nltk data download(stopwords)\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def text_process(mess):\n",
        "    \"\"\"\n",
        "    Takes in a string of text, then performs the following:\n",
        "    1. Remove all punctuation\n",
        "    2. Remove all stopwords\n",
        "    3. Returns a list of the cleaned text\n",
        "    \"\"\"\n",
        "    STOPWORDS = stopwords.words('english') + ['u', 'ü', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure', 'ltgt']\n",
        "    # Check characters to see if they are in punctuation\n",
        "    nopunc = [char for char in mess if char not in string.punctuation]\n",
        "\n",
        "    # Join the characters again to form the string.\n",
        "    nopunc = ''.join(nopunc)\n",
        "\n",
        "    # Now just remove any stopwords\n",
        "    return ' '.join([word for word in nopunc.split() if word.lower() not in STOPWORDS])\n",
        "\n",
        "# 'text' 컬럼에 text_process 함수 적용\n",
        "data['clean_msg'] = data['text'].apply(text_process)\n",
        "\n",
        "data.head()\n"
      ],
      "metadata": {
        "id": "jP_0o0ec48iH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 두 개의 빈 딕셔너리(스팸, 일반) 초기화하여 스팸 메시지와 일반 메시지 단어 빈도 저장\n",
        "ham_words = {}\n",
        "spam_words = {}\n",
        "\n",
        "for idx, email in data.iterrows():\n",
        "    for word in email['clean_msg'].split():\n",
        "        if email['label'] == 0:\n",
        "            # 해당 단어의 빈도를 ham_words 딕셔너리에서 1 증가\n",
        "            # 만약 해당 단어가 딕셔너리에 없다면 기본값 0을 사용\n",
        "            ham_words[word] = ham_words.get(word, 0) + 1\n",
        "        else:\n",
        "            # 만약 해당 이메일이 스팸 메시지라면\n",
        "            # 해당 단어의 빈도를 spam_words 딕셔너리에서 1 증가\n",
        "            # 만약 해당 단어가 딕셔너리에 없다면 기본값 0을 사용\n",
        "            spam_words[word] = spam_words.get(word, 0) + 1\n",
        "\n",
        "print(ham_words)\n",
        "print(spam_words)"
      ],
      "metadata": {
        "id": "WvlxOeP-GQcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_ham_words = sum(ham_words.values())  # 햄 메시지에서의 총 단어 수\n",
        "total_spam_words = sum(spam_words.values())  # 스팸 메시지에서의 총 단어 수\n",
        "\n",
        "print(total_ham_words, total_spam_words)\n",
        "\n",
        "# ham_words와 spam_words 딕셔너리의 키(단어)들을 합쳐서 중복을 제거\n",
        "total_words = len(set(list(ham_words.keys()) + list(spam_words.keys())))  # 전체 고유 단어 수\n",
        "\n",
        "print(total_words)\n",
        "\n",
        "N_ham = len(data[data['label'] == 0])  # 햄 메시지의 수\n",
        "N_spam = len(data[data['label'] == 1])  # 스팸 메시지의 수\n",
        "N_total = len(data)  # 전체 메시지의 수\n",
        "\n",
        "print(N_ham, N_spam, N_total)\n",
        "\n",
        "# 𝑃 ̂(𝑐_𝑗 )=𝑁_(𝑐_𝑗 )/𝑁_𝑡𝑜𝑡𝑎𝑙 공식을 사용하여 햄 및 스팸 메시지의 비율을 계산\n",
        "P_ham = N_ham / N_total  # 햄 메시지의 비율\n",
        "P_spam = N_spam / N_total  # 스팸 메시지의 비율\n",
        "\n",
        "print(P_ham, P_spam) # 일반, 스팸 비율"
      ],
      "metadata": {
        "id": "tb9IR9wAGUCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# score 계산\n",
        "def calculate_score(sentence, label_words, total_words_class):\n",
        "    score = 1\n",
        "    for word in sentence.split():\n",
        "        if word in label_words:\n",
        "            score *= (label_words[word] + 1) / (total_words_class + total_words)\n",
        "        else:\n",
        "            score *= 1 / (total_words_class + total_words)\n",
        "    return score"
      ],
      "metadata": {
        "id": "dK4q2gBTsbXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 𝑝(𝑤_𝑖│𝑐)= (𝑐𝑜𝑢𝑛𝑡(𝑤_𝑖,𝑐)+1)/((∑_(𝑤∈𝑉) 𝑐𝑜𝑢𝑛𝑡(𝑤,𝑐) )+|𝑉|)\n",
        "def calculate_ham_spam_scores(email):\n",
        "    ham_score = P_ham * calculate_score(email, ham_words, total_ham_words)\n",
        "    spam_score = P_spam * calculate_score(email, spam_words, total_spam_words)\n",
        "    return ham_score, spam_score\n",
        "\n",
        "# 각 메일에 대한 스팸 및 햄 점수를 계산\n",
        "scores = X_test.apply(calculate_ham_spam_scores)\n",
        "\n",
        "#print(scores)\n",
        "\n",
        "# 계산된 점수를 DataFrame에 새로운 열로 추가\n",
        "X_test_with_scores = X_test.to_frame()  # Series to DataFrame\n",
        "X_test_with_scores['ham_score'] = scores.apply(lambda x: x[0])\n",
        "X_test_with_scores['spam_score'] = scores.apply(lambda x: x[1])\n",
        "\n",
        "print(X_test_with_scores.head())\n"
      ],
      "metadata": {
        "id": "Do8lwf2oGaGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "# 1. 학습 데이터만 사용하여 spam/ham 단어 빈도를 계산\n",
        "train_data = pd.DataFrame({'text': X_train, 'label': y_train})\n",
        "\n",
        "words = train_data[train_data.label==0].text.apply(lambda x: [word.lower() for word in x.split()])\n",
        "ham_words = Counter()\n",
        "for msg in words:\n",
        "    ham_words.update(msg)\n",
        "\n",
        "words = train_data[train_data.label==1].text.apply(lambda x: [word.lower() for word in x.split()])\n",
        "spam_words = Counter()\n",
        "for msg in words:\n",
        "    spam_words.update(msg)\n",
        "\n",
        "# 2. 이 단어 빈도를 기반으로 테스트 데이터의 스코어를 계산\n",
        "scores = X_test.apply(calculate_ham_spam_scores)\n",
        "X_test_with_scores = X_test.to_frame()\n",
        "X_test_with_scores['ham_score'] = scores.apply(lambda x: x[0])\n",
        "X_test_with_scores['spam_score'] = scores.apply(lambda x: x[1])\n",
        "\n",
        "# 원본 데이터에 스코어 추가\n",
        "data = pd.merge(data, X_test_with_scores[['ham_score', 'spam_score']], left_index=True, right_index=True, how='left')\n",
        "\n",
        "# ... 중략 ...\n",
        "#이렇게 위치시키면 학습 데이터를 기반으로 스팸/햄 단어 빈도를 계산하고, 그 후 테스트 데이터의 스코어를 계산하는 것이 더 자연스러워집니다.\n",
        "\n",
        "# 원본 데이터에 스코어 추가\n",
        "#data.drop(columns=['ham_score_x', 'spam_score_x', 'ham_score_y', 'spam_score_y'], inplace=True)\n",
        "\n",
        "#data = pd.merge(data, X_test_with_scores[['ham_score', 'spam_score']], left_index=True, right_index=True, how='left')\n",
        "data = pd.merge(data, X_test_with_scores[['ham_score', 'spam_score']], left_index=True, right_index=True, how='left', suffixes=('', '_test'))\n",
        "\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "9tp9YuD5Ga4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_word_probabilities(sentence, label_words, total_words_class):\n",
        "    word_probabilities = {}\n",
        "    for word in sentence.split():\n",
        "        if word in label_words:\n",
        "            word_probabilities[word] = (label_words[word] + 1) / (total_words_class + total_words)\n",
        "        else:\n",
        "            word_probabilities[word] = 1 / (total_words_class + total_words)\n",
        "    return word_probabilities\n",
        "\n",
        "# 테스트 데이터의 head 부분에 대해서 각 단어의 확률을 계산\n",
        "word_probs_ham = X_test.head().apply(lambda x: calculate_word_probabilities(x, ham_words, total_ham_words))\n",
        "word_probs_spam = X_test.head().apply(lambda x: calculate_word_probabilities(x, spam_words, total_spam_words))\n",
        "\n",
        "print(\"Word Probabilities for Ham(일반):\")\n",
        "print(word_probs_ham)\n",
        "print(\"\\nWord Probabilities for Spam(스팸):\")\n",
        "print(word_probs_spam)\n"
      ],
      "metadata": {
        "id": "IgFIYgClwr3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# 1. 테스트 데이터에 대한 예측값 계산\n",
        "y_pred_test = X_test_with_scores.apply(lambda row: 1 if row['spam_score'] > row['ham_score'] else 0, axis=1)\n",
        "#위의 코드는 X_test_with_scores DataFrame의 각 행에 대하여 spam_score와 ham_score를 비교\n",
        "#만약 spam_score가 ham_score보다 크다면, 해당 메일은 스팸(1)으로 예측되고 그렇지 않다면 햄(0)으로 예측됨\n",
        "\n",
        "# 2. 테스트 데이터의 실제 라벨과 예측값을 사용하여 성능 평가\n",
        "# 매트릭스 출력\n",
        "cm_test = confusion_matrix(y_test, y_pred_test)\n",
        "print(\"Confusion Matrix for Test Data:\")\n",
        "print(cm_test)\n",
        "\n",
        "# 정확도 출력\n",
        "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
        "print(f\"Accuracy for Test Data: {accuracy_test:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "a5KX9IBKHIsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "True Negative (TN): 실제로 햄 메일인데, 햄으로 예측한 것.\n",
        "\n",
        "False Positive (FP): 실제로 햄 메일인데, 스팸으로 잘못 예측한 것.\n",
        "\n",
        "False Negative (FN): 실제로 스팸인데, 햄으로 잘못 예측한 것.\n",
        "\n",
        "True Positive (TP): 실제로 스팸이며, 스팸으로 올바르게 예측한 것.\n",
        "\n",
        "TN = 850: 850개의 햄 메일이 올바르게 햄으로 예측\n",
        "\n",
        "FP = 53: 53개의 햄 메일이 스팸으로 잘못 예측\n",
        "\n",
        "FN = 12: 12개의 스팸 메일이 햄으로 잘못 예측\n",
        "\n",
        "TP = 119: 119개의 스팸 메일이 올바르게 스팸으로 예측\n",
        "\n",
        "Accuracy=  TP+TN​ / TP+TN+FP+FN\n",
        "\n",
        "테스트 데이터에 대해 모델의 예측 정확도는 약 93.71%"
      ],
      "metadata": {
        "id": "qN1WfG8aMQIF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---- 아래는 이전과제 코드 ----"
      ],
      "metadata": {
        "id": "6i6_lT08fdvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "#ham(not spam) word count\n",
        "words = data[data.label==0].clean_msg.apply(lambda x: [word.lower() for word in x.split()])\n",
        "ham_words = Counter()\n",
        "\n",
        "for msg in words:\n",
        "    ham_words.update(msg)\n",
        "\n",
        "print(ham_words.most_common(50))"
      ],
      "metadata": {
        "id": "iMLKBitg7d-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#spam word count\n",
        "words = data[data.label==1].clean_msg.apply(lambda x: [word.lower() for word in x.split()])\n",
        "spam_words = Counter()\n",
        "\n",
        "for msg in words:\n",
        "    spam_words.update(msg)\n",
        "\n",
        "print(spam_words.most_common(50))"
      ],
      "metadata": {
        "id": "eE2cDVi88vQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_ham  = data[data['label'] == 0].copy()\n",
        "data_spam = data[data['label'] == 1].copy()"
      ],
      "metadata": {
        "id": "7ZLmoF9Q_Bhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_wordcloud(data_spam_or_ham, title):\n",
        "    text = ' '.join(data_spam_or_ham['text'].astype(str).tolist())\n",
        "    stopwords = set(wordcloud.STOPWORDS)\n",
        "\n",
        "    fig_wordcloud = wordcloud.WordCloud(stopwords=stopwords,background_color='lightgrey',\n",
        "                    colormap='viridis', width=800, height=600).generate(text)\n",
        "\n",
        "    plt.figure(figsize=(10,7), frameon=True)\n",
        "    plt.imshow(fig_wordcloud)\n",
        "    plt.axis('off')\n",
        "    plt.title(title, fontsize=20 )\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Z5VMX0Ac_GA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train))\n",
        "print(len(y_train))\n",
        "\n",
        "print(len(X_train_encoded))\n",
        "print(len(X_train_padded))"
      ],
      "metadata": {
        "id": "igkUzzxvBiR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Embedding, SimpleRNN\n",
        "from tensorflow.python.keras.engine.sequential import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "\n",
        "embedding_dim = 32\n",
        "hidden_units = 32\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(SimpleRNN(hidden_units))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(X_train_padded, y_train.astype(int), epochs=4, batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "id": "TxJ6oFuMxCOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess for test data\n",
        "X_test_encoded = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_padded = pad_sequences(X_test_encoded, maxlen=max_len)\n",
        "\n",
        "#Model evaluation (딥러닝 기반 모델성능)\n",
        "loss, accuracy = model.evaluate(X_test_padded, y_test.astype(int), batch_size=64)\n",
        "print(\"테스트 정확도:\", accuracy)"
      ],
      "metadata": {
        "id": "11TQbyKc_lMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "\n",
        "\n",
        "pipe = Pipeline([('bow', CountVectorizer()),\n",
        "                 ('tfid', TfidfTransformer()),\n",
        "                 ('model', MultinomialNB())]) # 나이브 베이즈"
      ],
      "metadata": {
        "id": "0Cm3yVgmJMIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "RuXcTe1_JN-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pipe.predict(X_test)"
      ],
      "metadata": {
        "id": "yru80uEfJRuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score, f1_score\n",
        "\n",
        "# For Naive Bayes model\n",
        "print(\"=======Accuracy Score===========\")\n",
        "print(metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Print Recall\n",
        "print(\"=======Recall Score===========\")\n",
        "print(recall_score(y_test, y_pred))\n",
        "\n",
        "# Print F1-Score\n",
        "print(\"=======F1 Score===========\")\n",
        "print(f1_score(y_test, y_pred))\n",
        "\n",
        "# print the confusion matrix\n",
        "print(\"=======Confusion Matrix===========\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "qS_MksdFJVhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy (정확도) - 0.9526 (95.26%):\n",
        "\n",
        "95.26%가 올바르게 예측됨.\n",
        "(딥러닝 기반 모델은 0.9806576371192932로 나옴)\n",
        "\n",
        "Recall (재현율) - 0.6259 (62.59%):\n",
        "\n",
        "실제 SPAM 메일 중 얼마나 많은 메일이 SPAM으로 올바르게 예측되었는지를 나타냄. 여기서의 결과는 62.59%로, 실제 SPAM 메일 중 약 62.59%만이 SPAM으로 올바르게 분류되었다는 것을 확인할 수 있음.\n",
        "즉, SPAM 메일의 약 37.41%는 HAM으로 잘못 분류되었음.\n",
        "\n",
        "F1 Score - 0.77 (77%):\n",
        "\n",
        "F1 스코어는 정밀도와 재현율의 조화 평균으로 정밀도와 재현율의 균형을 나타내며, 특히 불균형한 데이터셋에서 유용함.\n",
        "여기서는 77%로, 분류기의 전반적인 성능을 나타내며 중요한 지표 중 하나\n",
        "\n",
        "혼동 행렬(Confusion Matrix):\n",
        "array([[903, 0], [49, 82]])는 혼동 행렬을 나타냄.\n",
        "\n",
        "True Negative (TN): 903개 - 실제로 'ham'(정상 메시지)이며, 모델도 'ham'으로 분류한 경우.\n",
        "False Positive (FP): 0개 - 실제로 'ham'인데, 모델이 'spam'으로 잘못 분류한 경우.\n",
        "False Negative (FN): 49개 - 실제로 'spam'인데, 모델이 'ham'으로 잘못 분류한 경우.\n",
        "True Positive (TP): 82개 - 실제로 'spam'이며, 모델도 'spam'으로 올바르게 분류한 경우.\n",
        "\n",
        "해석:\n",
        "\n",
        "1. 모델은 'ham' 메시지를 매우 잘 분류하며, 모든 'ham' 메시지를 올바르게 'ham'으로 분류함 (FP = 0).\n",
        "2. 그러나 'spam' 메시지 중 일부를 잘못 분류함. 49개의 'spam' 메시지를 'ham'으로 잘못 분류하였음.\n",
        "3. SPAM 메일을 잘 감지하는 능력 (재현율)은 상대적으로 낮습니다 (62.59%).\n",
        "이는 SPAM 메일 중 약 37%를 놓친다는 것을 의미하며, 이것은 SPAM 필터링에서 중요한 문제가 될 수 있음.\n",
        "4. F1 스코어는 77%로 나쁘지 않은 성능을 나타냄.\n",
        "5. 전반적으로 Confusion Matrix를 통해 모델이 실제 HAM 메일에 대해 매우 안정적인 성능을 보여주고 있음을 확인할 수 있음.\n",
        "\n"
      ],
      "metadata": {
        "id": "tvdZ0Ny7JsbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "# 추가 코드, 스팸판단 유무 (위 코드와 독립적)\n",
        "def predict_spam(model, tokenizer, text, max_len):\n",
        "\n",
        "    # 토큰화\n",
        "    encoded_text = tokenizer.texts_to_sequences([text])\n",
        "\n",
        "    # 패딩 처리\n",
        "    padded_text = pad_sequences(encoded_text, maxlen=max_len, padding='post')\n",
        "\n",
        "    # 모델 예측\n",
        "    prediction = model.predict(padded_text)\n",
        "\n",
        "    # 예측 결과와 예측값 출력\n",
        "    print(f\"Prediction Value: {prediction[0][0]:.4f}\")\n",
        "    if prediction > 0.5:\n",
        "        print(\"This is SPAM!\")\n",
        "    else:\n",
        "        print(\"This is NOT spam!\")\n",
        "\n",
        "# 사용 예제\n",
        "text_samples = [\n",
        "    \"Your free ringtone is waiting to be collected.\",\n",
        "    \"Click here for gain money!\",\n",
        "    \"Congratulations! You've won a $1000 gift card. Click here to claim.\",\n",
        "    \"Hi, are you available for a meeting tomorrow?\",\n",
        "    \"Your bank account has been compromised. Please send us your credentials.\",\n",
        "    \"Submission of the teaching journal in September\"\n",
        "]\n",
        "\n",
        "for text in text_samples:\n",
        "    print(f\"Testing for text: {text}\")\n",
        "    predict_spam(model, tokenizer, text, max_len)\n",
        "    print(\"-------------------------------\")\n"
      ],
      "metadata": {
        "id": "KRziaOjLFNJ9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}